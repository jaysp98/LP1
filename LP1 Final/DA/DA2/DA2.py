# -*- coding: utf-8 -*-
"""Copy of LP1Da2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BvZXQ6vdYKVB8s0COdSuMedoLy2Pwe2L
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
# %matplotlib inline

import matplotlib.pyplot as plt
import seaborn as sns

data=pd.read_csv('Pima.csv')

data.head(5) #########printing data

data.shape ##########how many features and rows

data.info()  ### info about dataset  2.2 Sumarraizing dataset for prediction

data['x1'].describe()  ###statistics similary of others

data.dtypes  ## datatypes

from sklearn.model_selection import train_test_split
train,test=train_test_split(diab,test_size=0.25,random_state=0,stratify=diab['Outcome'])# stratify the outcome
train_X=train[train.columns[:8]]
test_X=test[test.columns[:8]]
train_Y=train['Outcome']
test_Y=test['Outcome']

'''train=np.array(data.iloc[0:600])  ##2.1 Loading data into training and testing
test=np.array(data.iloc[600:768])

train.shape  ### traiinging data size

test.shape ### testing datasize'''

from sklearn.naive_bayes import GaussianNB   ####importing guassian model

model = GaussianNB()

model.fit(train_X, train_Y)  ##2.3 training the data for prediction

predicted= model.predict(test_X)
from sklearn.metrics import confusion_matrix
confusion_matrix = confusion_matrix(test_Y, prediction)
print(confusion_matrix)
print('The accuracy of the Logistic Regression is',metrics.accuracy_score(predicted,test_Y))


'''print(test[:,8])
print(predicted)  ## predicted data

count=0            ###### calulating acuracy
for l in range(168):
    if(predicted[l]==test[l,8]):
        count=count+1

print(count)  ###### print no of correctly matched samples out of 168

############ Accuracy is


print(count/168)'''
